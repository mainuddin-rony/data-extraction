{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_city_state(state_city_txt):\n",
    "    city = 'N/A'\n",
    "    state = 'N/A'\n",
    "    if 'call' in state_city_txt.lower():\n",
    "        return 'N/A', 'N/A'\n",
    "    city_state = re.sub(r'([^\\s\\w]|_)+', '', state_city_txt).split()\n",
    "    if len(city_state) > 1:\n",
    "        state = city_state[-1]\n",
    "        city = ' '.join(city_state[:-1])\n",
    "    else:\n",
    "        city = city_state[0]\n",
    "    \n",
    "    return city, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_car_rows(car_rows):\n",
    "    car_list = []\n",
    "    for car in car_rows:\n",
    "        single_car = {}\n",
    "        if car.find('a', class_='result-title') != None:\n",
    "            single_car['Url'] = car.find('a', class_='result-title')['href']\n",
    "        else:\n",
    "            single_car['Url'] = 'N/A'\n",
    "        if car.find('a', class_='result-title') != None:\n",
    "            single_car['Title'] = car.find('a', class_='result-title').get_text()\n",
    "        else:\n",
    "            single_car['Title'] = 'N/A'\n",
    "        if car.find('span', class_='result-price') != None:\n",
    "            single_car['Price'] = car.find('span', class_='result-price').get_text()[1:]\n",
    "        else:\n",
    "            single_car['Price'] = 'N/A'\n",
    "        if car.find('span', class_='result-hood') != None:\n",
    "            single_car['City'], single_car['State'] = get_city_state(car.find('span', class_='result-hood').get_text())\n",
    "        else:\n",
    "            single_car['City'], single_car['State'] = 'N/A', 'N/A'\n",
    "        car_list.append(single_car)\n",
    "    return car_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://northmiss.craigslist.org/search/cta?s=0\")\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_rows = soup.find_all('li', class_='result-row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cars = handle_car_rows(car_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_df = pd.DataFrame.from_dict(all_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_df.to_csv('part_1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_val = 0\n",
    "has_next = True\n",
    "all_page_cars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while has_next:\n",
    "    page = requests.get(\"https://northmiss.craigslist.org/search/cta?s=\" + str(s_val))\n",
    "    if page.status_code == 200:\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        car_rows = soup.find_all('li', class_='result-row')\n",
    "        if len(car_rows) > 0:\n",
    "            all_page_cars += handle_car_rows(car_rows)\n",
    "            s_val += 120\n",
    "        else:\n",
    "            has_next = False\n",
    "    else:\n",
    "        has_next = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_page_cars_df = pd.DataFrame.from_dict(all_page_cars)\n",
    "all_page_cars_df.to_csv('part_2.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_car_infos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, value in all_page_cars_df.iterrows():\n",
    "    car_url = value['Url']\n",
    "    page_rq = requests.get(car_url)\n",
    "    if page_rq.status_code == 200:\n",
    "        each_car = {}\n",
    "        each_car['Url'], each_car['Time'], each_car['Num_Image'], each_car['Description'], each_car['Year'], each_car['Make_Model'], each_car['Condition'], each_car['Cylinders'], each_car['Drive'], each_car['Fuel'], each_car['Odometer'], each_car['Paint_Color'], each_car['Size'], each_car['Title_Status'], each_car['Transmission'], each_car['VIN'] = ['N/A'] * 16\n",
    "        soup = BeautifulSoup(page_rq.content, 'html.parser')\n",
    "        each_car['Url'] = car_url\n",
    "        if soup.find('time', class_='date timeago') != None:\n",
    "            posted_date = soup.find('time', class_='date timeago').text\n",
    "            each_car['Time'] = posted_date.strip()\n",
    "        if soup.find('span', class_='slider-info') != None:\n",
    "            each_car['Num_Image'] = int(soup.find('span', class_='slider-info').text.split()[-1])\n",
    "        if soup.find('section', id='postingbody') != None:\n",
    "            description = soup.find('section', id='postingbody').text\n",
    "            each_car['Description'] = description.strip().replace(\"\\n\", \"\").replace(\"\\t\",\"\").replace(\"QR Code Link to This Post\",\"\")\n",
    "        attributes = soup.find_all('p', class_='attrgroup')\n",
    "        if len(attributes) > 0:\n",
    "            if attributes[0].find('span') != None:\n",
    "                title_year = attributes[0].find('span').text.split()\n",
    "                if len(title_year) > 0:\n",
    "                    each_car['Year'] = int(title_year[0])\n",
    "                    each_car['Make_Model'] = ' '.join(title_year[1:])\n",
    "            if len(attributes) > 1:\n",
    "                other_attrs = attributes[1].find_all('span')\n",
    "                if len(other_attrs) > 0:\n",
    "                    for att in other_attrs:\n",
    "                        att_text = att.text\n",
    "                        param_name = att_text.split(\":\")[0].title()\n",
    "                        param_val = ' '.join(att_text.split(\":\")[1:])\n",
    "                        if len(param_name.split()) > 0:\n",
    "                            param_name = '_'.join(param_name.split())\n",
    "                        if param_name.lower() == 'vin':\n",
    "                            param_name = \"VIN\"\n",
    "                        each_car[param_name] = param_val\n",
    "        all_car_infos.append(each_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_car_info_df = pd.DataFrame.from_dict(all_car_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_car_info_df.drop(['Cryptocurrency_Ok', 'Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_car_info_df.to_csv('part_3.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_car_info_df = pd.read_csv('part_3.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_car_info_df = all_car_info_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(all_page_cars_df, all_car_info_df, on='Url', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2306, 20)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2296, 5)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.to_csv('part_3.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2296, 19)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_car_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Condition', 'Cryptocurrency_Ok', 'Cylinders', 'Description', 'Drive',\n",
       "       'Fuel', 'Make_Model', 'Num_Image', 'Odometer', 'Paint_Color', 'Size',\n",
       "       'Time', 'Title_Status', 'Transmission', 'Type', 'Url', 'VIN', 'Vin',\n",
       "       'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_car_info_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Url, Time, Num_Image, Description, Year, Make_Model, Condition, Cylinders, Drive, Fuel, Odometer, Paint_Color, Size, Title_Status, Transmission, VIN"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
